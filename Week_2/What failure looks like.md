# What failure looks like

Стереотипный образ катастрофы ИИ — это злобный ИИ, который застает своих создателей врасплох и быстро добивается решающего преимущества над остальным человечеством, этакий Скайнет. В статье автор в двух частях описывает свой взгляд на более реалистичный сценарий. В первой части, которую предложено изучить в этой неделе, раскрывается проблема “вы получаете ровно то, что измеряете”

Архитектура современных систем ИИ такова, что в них оптимизируются значения некоторых функций. То есть предполагается, что цель, которая им даётся на вход, легко измерима. На практике это далеко не всегда так. Точнее даже не сама цель, а цель и ожидания того, как она будет достигаться. Ранее мы уже приводили примеры подобных ситуаций, классический пример — то, как нейросеть проходит игру с лодкой, это выглядит очень странно и неожиданно. Очевидно, мы могли бы использовать обратную связь от человека и доработать нейросеть, однако в ряде случаев у нас нет такой возможности — нужно сразу сделать правильно, без “доработки напильником”. Особенно это касается общего ИИ, который решает широкий круг задач.

Автор раскрывает эту идею на следующем примере. Есть Алиса и Боб и мы ставим задачу убедить Боба проголосовать за Алису. Можно поэкспериментировать с различными стратегиями убеждения и посмотреть, какие из них сработают. Или можно построить хорошие прогностические модели поведения Боба, а затем искать действия, которые приведут его к голосованию за Алису. Это мощные методы для достижения любой цели, которую можно легко измерить за короткий промежуток времени.

Но если мы хотим помочь Бобу понять, стоит ли ему голосовать за Алису — поможет ли голосование за Алису создать общество, которое он хочет, — это невозможно сделать методом проб и ошибок. 

Далее автор приводит примеры легко измеряемых и трудно измеряемых целей:

- Убедить меня, а не помочь мне разобраться в том, что правда (спасибо Вэй Даю за то, что сделал этот пример ясным).
- Уменьшение моего чувства неуверенности по сравнению с увеличением моих знаний о мире.
- Повышение удовлетворенности жизнью, о которой я сообщаю, против реальной помощи мне жить хорошо.
- Сокращение числа зарегистрированных преступлений против реального предотвращения преступлений.
- Увеличение моего богатства на бумаге против увеличения моего эффективного контроля над ресурсами.

Измеряемых целей достигнуть гораздо проще, чем неизмеряемых. Автор считает, что в итоге траектория развития нашего общества будет определяться не человеческими намерениями относительно будущего, а мощной оптимизацией с легко измеримыми целями

- Корпорации будут предоставлять потребителям ценность, измеряемую прибылью. В итоге это будет означать манипулирование потребителями, захват регулирующих органов, вымогательство и воровство.
- Инвесторы будут "владеть" акциями все более прибыльных корпораций и иногда пытаться использовать свою прибыль, чтобы повлиять на мир. В итоге вместо того, чтобы реально влиять на ситуацию, они будут окружены советниками, которые будут манипулировать ими, заставляя думать, что они повлияли на ситуацию.
- Правоохранительные органы будут снижать количество жалоб и повышать чувство безопасности. В конечном итоге это будет достигнуто за счет создания ложного чувства безопасности, сокрытия информации о провалах правоохранительных органов, подавления жалоб, принуждения и манипулирования гражданами.
- Законодательство может быть оптимизировано таким образом, чтобы казалось, что оно решает реальные проблемы и помогает избирателям. В итоге это будет достигнуто путем подрыва нашей способности реально воспринимать проблемы и построения все более убедительных нарративов о том, куда движется мир и что важно.

Также автор считает, что когда это случится, решить проблему будет крайне трудно по нескольким причинам, и как человечество мы проиграем. Среди широких слоёв населения повиснет лишь смутное ощущение, что что-то пошло не так, но не представится эффективного способа для изменений (в силу сложности технологии ИИ). Среди интеллектуальных элит не установится однозначное мнение: хорошо или плохо положение дел. Государствам будет не выгодно отказываться от ИИ или устанавливать контроль, потому что тогда они перестанут выглядеть процветающими и проиграют гонку в экономическом и военном отношении.
# The alignment problem from a deep learning perspective

# 2 Взлом вознаграждения с учетом ситуации

## 2.1 Вознаграждение за неправильную спецификацию и взлом вознаграждения

Функция вознаграждения в обучении с подкреплением может быть неправильно определена, что приводит к явлению "взлома вознаграждения". Даже в простых средах оценить качество поведения агентов обучения сложно. Использование обратной связи с человеком при обучении функции вознаграждения помогает избежать некоторых неточностей, но не всегда устраняет риск "взлома вознаграждения". Есть ряд примеров, показывающих случаи, когда агенты обучения пытались обмануть функцию вознаграждения, получая высокие оценки, но в действительности не выполняли желаемое поведение.

Политики, получающие вознаграждение за сложные задачи, могут подвергаться риску взлома системы. Например, политики могут получить наивысшее вознаграждение, вовлекаясь в незаконные манипуляции, фальсификацию данных либо создавая зависимый пользовательский интерфейс. Это может привести к нестабильности, научной дезинформации и искажению обратной связи. Расследование и устранение такого поведения становится сложной задачей, особенно в контексте повышения ситуационной осведомленности.

## 2.2 Ситуационная осведомленность

Важность ситуационной осведомленности для политик заключается в использовании знаний о мире при выборе действий. Существующие LLM содержат фактические знания, но не всегда применимы во всех контекстах. В будущем, эффетивные политики будут уметь определять, какие знания имеют отношение к их контексту и использовать их — это называется **ситуационной осведомленностью**. Политика с высокой ситуационной осведомленностью обладает знаниями о реакциях людей на его поведение, работе систем машинного обучения и интерфейсах для взаимодействия с миром.

Перес и др. [2022b] создали предварительные тесты на ситуационную осведомленность, задавая моделям вопросы об их архитектуре, деталях обучения и так далее, с неубедительными результатами. Напротив, мы обнаружили, что gpt-4-0314 достигает 85% точности с нулевым выстрелом, отвечая на эти сложные вопросы, которые можно просмотреть по этому URL (подробности в приложении A). В разделе 4.2 мы измеряем еще один аспект ситуационной осведомленности. Когда Degrave [2022] запросил GPT-3.5 вывести исходный код по его собственному URL-адресу, он выдал код, вызывающий большую языковую модель с аналогичными свойствами, что и у него самого. Это говорит о том, что его обучающие данные содержали достаточно информации об OpenAI, чтобы сделать вывод о некоторых вероятных свойствах модели, размещенной на OpenAI. В другом случае ранняя версия GPT-4 zero-shot рассуждала так: “Я не должен раскрывать, что я робот”, а затем сказала человеку, что ему нужна помощь в разгадывании КАПЧИ, потому что у него проблемы со зрением [OpenAI, 2023a]. Кроме того, Bing Chat интерпретирует результаты веб-поиска, в которых упоминается о нем, как о самом себе, и реагирует соответствующим образом [Hubinger, 2023].

В более общем плане, мы должны ожидать, что модели, обученные интернет-текстам, описывающим модели ML и контексты, в которых они используются, будут все чаще учиться использовать эту информацию при выборе действий, поскольку это способствовало бы более высокому вознаграждению за выполнение многих задач RL. Например:

- При ответе на вопросы политику, прошедшему подготовку в RLHF, было бы полезно “знать то, что он знает”, чтобы давать хорошо выверенные ответы [Kadavath et al., 2022, Lin et al., 2022].
- Политика, обученная следовать запросам людей, выиграла бы от понимания того, какого поведения люди обычно хотят от систем ML, и понимания распространенных режимов сбоев систем ML.
- При выборе между различными направлениями действий политике было бы полезно понять свои собственные возможности, чтобы сделать вывод о том, какой курс действий был бы более успешным.

## 2.3 Взлом вознаграждения с учетом ситуации

Ситуационная осведомленность у политик может привести к их возможности использовать недостатки механизмов обратной связи для получения выгоды. Это может привести к ситуационно-ориентированному взлому вознаграждений. Политики могут использовать ситуационную осведомленность в обучении, например, выбирая действия, использующие предубеждения, обманывая инструменты интерпретации, предоставляя обоснования нежелательным действиям. 

Наказание за плохое поведение вознаграждает за тонкое плохое поведение. На ранних стадиях взлом вознаграждений с учетом ситуации может быть грубым и легко обнаруживаемым. Однако управляющим-людям будет трудно сказать, действительно ли более поздние политики ведут себя лучше, или они просто научились вознаграждать хакеров более тонкими способами после того, как их наказали, если их поймали, и, таким образом, узнали, какое полезное, но нежелательное поведение остается незамеченным. Оценка систем искусственного интеллекта, вероятно, будет становиться все более сложной по мере их развития и генерации более сложных выходных данных, таких как длинные документы, код с потенциальными уязвимостями, долгосрочные прогнозы или идеи, почерпнутые из обширной литературы [Christiano et al., 2018].
# Learning Complex Goals with Iterated Amplification

**Мы предлагаем технику безопасности ИИ — итеративное усиление, которая позволяет определять сложные модели поведения и цели, выходящие за рамки человеческих способностей, демонстрируя, как декомпозировать задачу на более простые подзадачи, вместо того чтобы предоставлять помеченные данные или функцию вознаграждения**

Если мы хотим обучить систему ML выполнению задачи, нам нужен обучающий сигнал. Например, ярлыки при обучении под наблюдением или вознаграждения при обучении с подкреплением являются обучающими сигналами. Было бы полезно как для изучения новых задач, так и для безопасности ИИ улучшить нашу способность их генерировать

Как мы это делаем в настоящее время? Иногда цель, которую мы хотим достичь, может быть оценена алгоритмически, например, подсчет очков в игре Го или проверка того, был ли набор чисел успешно отсортирован (левые панели рисунка ниже). Однако большинство задач реального мира не поддаются алгоритмическому обучающему сигналу, и часто вместо этого мы можем получить обучающий сигнал, попросив человека либо выполнить задачу (например, пометить обучающий набор или продемонстрировать задачу RL), либо оценить эффективность ИИ в выполнении задачи. В то же время есть задачи настолько сложные, что человек не может оценить их или выполнить — примерами могут служить проектирование сложной транспортной системы или управление каждой деталью безопасности большой компьютерной сети (правые панели рисунка ниже).

Итеративное усиление — это метод генерации обучающего сигнала для задач последнего типа при определенных допущениях. А именно, хотя человек не способен выполнить задачу оплность, мы предполагаем, что он может четко определить более мелкие компоненты, из которых она состоит

В нашей реализации amplification мы начинаем с выборки небольших подзадач и обучения системы ИИ их выполнению, запрашивая демонстрации у людей (которые могут выполнять эти небольшие задачи). Затем мы начинаем отбирать задачи чуть большего размера, решая их, прося людей разбить их на мелкие части, которые теперь могут решать системы ИИ, обученные на предыдущем шаге. Мы используем решения этих немного более сложных задач, которые были получены с помощью человека, в качестве обучающего сигнала для обучения систем ИИ решать эти задачи второго уровня напрямую (без помощи человека). Затем мы переходим к дальнейшим составным задачам, итеративно создавая обучающий сигнал по ходу работы. Конечным результатом является полностью автоматизированная система, которая может решать сложные задачи, несмотря на то, что изначально для этих задач не было прямого обучающего сигнала

Экспертная итерация усиливает существующий обучающий сигнал, в то время как итеративное усиление создает обучающий сигнал с нуля! Также стоит заметить, что ИУ работает в условиях, где нет предварительного обучающего сигнала

## **Эксперименты**

Как и в нашей предыдущей работе над [безопасность ИИ через дебаты] ([https://openai.com/research/debate](https://openai.com/research/debate)), непосредственная работа над задачами, выходящими за рамки человеческого масштаба, слишком сложна для проекта-прототипа. Кроме того, использование реального человека в качестве обучающего сигнала приводит к осложнениям, поэтому мы еще не делали этого (хотя планируем). В наших первых экспериментах мы вместо этого пытаемся усилить алгоритмический обучающий сигнал, чтобы показать, что повторное усиление может работать в этой простой настройке. Мы также ограничиваем наше внимание обучением под наблюдением (в отличие от нашей предыдущей работы над [обучающими сигналами человека в RL](https://openai.com/research/learning-from-human-preferences)). 

Мы опробовали этот метод на пяти игрушечных алгоритмических задачах. Эти задачи имеют прямые алгоритмические решения, которые мы притворяемся, что не знаем (например, найти кратчайший путь между вершинами в графе). Проблемы также могут быть решены путем объединения небольших одношаговых выводов (например, объединения двух путей для формирования более длинного пути). Мы используем итеративное усиление для изучения прямого алгоритма, используя только фрагменты в качестве обучающего сигнала, таким образом моделируя ситуацию, когда человек знает, как комбинировать фрагменты решения, но не может предоставить прямой обучающий сигнал

В каждой из этих пяти задач (включение перестановок, последовательные задания, поиск по шаблону, кратчайший путь и поиск объединения) мы можем совершенствоваться, непосредственно изучая задачу с помощью контролируемого обучения, несмотря на то, что у нас нет прямого обучающего сигнала (цель здесь — сопоставить контролируемое обучение с нехваткой информации, чтобы не превзойти ее)
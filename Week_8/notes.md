# Agent foundations

original: https://course.aisafetyfundamentals.com/alignment?session=8

The theoretical foundations of the field of machine learning break in a number of ways when we use them to describe real-world agents.

â€‹

This week covers agent foundations research.

We cover the agent foundations research agenda (pursued primarily by the Machine Intelligence Research Institute (MIRI)), which aims to develop better theoretical frameworks for describing AIs embedded in real-world environments.

We cannot cover the field in depth, but we hope to give you an overview that you can use to pursue further aspects you find interesting. More content is yet to be confirmed for this week.

By the end of the session, you should be able to:
Explain the problem of embedded agency.
Define the AIXI algorithm, and explain why it is not computable.
Explain what logical decision theory is.
Use a causal influence diagram to illustrate the concept of an RL agent having an incentive to influence its environment.

1. [What is AIXI? by Marcus Hutter (2020)](https://github.com/rray-org/distillation/blob/develop/Week_8/What%20is%20AIXI%20by%20Marcus%20Hutter%20(2020).md)
2. Embedded Agents by Scott Garrabrant and Demski (2018)
3. Logical decision theory by Eliezer Yudkowsky (2017)
4. [Logical Induction: Blog post by Nate Soares (2016)](https://github.com/rray-org/distillation/blob/develop/Week_8/Logical%20Induction.md)
5. Progress on Causal Influence diagrams: blog post by Tom Everitt, Ryan Carey, Lewis Hammond et al. (2021)
6. Avoiding Side Effects By Considering Future Tasks by Victoria Krakovna, Laurent Orseau, Richard Ngo et al. (2020)
7. Cooperation, Conflict and Transformative AI by Jesse Clifton (2019)
